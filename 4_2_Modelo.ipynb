{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Nos conectamos a nuestro conjunto de datos\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.optimizers.legacy import SGD\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# optimizador de la red por medio de Bayessian Optimization\n",
    "#  !pip install bayesian-optimization\n",
    "from bayes_opt import BayesianOptimization\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 22)\n",
      "(250, 22)\n",
      "(750, 224, 224, 3)\n",
      "(250, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# Abrimos nuestros dataset para prepararlo\n",
    "df_train = pd.read_csv('train_data.csv', sep=';', decimal='.')\n",
    "print(df_train.shape)\n",
    "\n",
    "df_test = pd.read_csv('test_data.csv', sep=';', decimal='.')\n",
    "print(df_test.shape)\n",
    "\n",
    "# Vamos a abrir las imágenes\n",
    "trainImagesX = np.load(\"trainImagesX.npy\")\n",
    "print(trainImagesX.shape)\n",
    "\n",
    "# Abrimos las imagenes de test\n",
    "testImagesX = np.load(\"testImagesX.npy\")\n",
    "print(testImagesX.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "for image in trainImagesX:\n",
    "    if image.shape >= (224, 224, 4):\n",
    "        print(image.shape)\n",
    "        plt.imshow(image)\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Escalamos las imagenes\n",
    "scaler = MinMaxScaler()\n",
    "x_train_images = scaler.fit_transform(trainImagesX)\n",
    "x_test_images = scaler.fit_transform(testImagesX)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Hacemos el split de train y test para las imágenes y los atributos\n",
    "# Lo hacemos con el dataframe completo, aún no separamos los valores\n",
    "\n",
    "split = train_test_split(df_train, x_train_images, test_size=0.1, random_state=42)\n",
    "(trainAttrX, valAttrX, trainImagesX, valImagesX) = split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Separamos x_train, y_train y convertimos a numpy\n",
    "x_train = trainAttrX.drop(['Price'], axis=1).values\n",
    "y_train = trainAttrX['Price'].values\n",
    "\n",
    "# Separamos x_test, y_test y convertimos a numpy\n",
    "x_test = df_test.drop(['Price'], axis=1).values\n",
    "y_test = df_test['Price'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the scaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to the training data\n",
    "scaler.fit(x_train)\n",
    "\n",
    "# Transform the training and test data\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, Dropout, Conv2D, Activation, BatchNormalization, MaxPooling2D\n",
    "from tensorflow.keras import optimizers, Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "import locale\n",
    "from matplotlib import image as mpimg\n",
    "import matplotlib.gridspec as gridspec\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\n",
    "\n",
    "def train_deep_net(width, height, depth, filters=(16, 32, 64), regress=False):\n",
    "    # initialize the input shape and channel dimension, assuming\n",
    "    # TensorFlow/channels-last ordering\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "\n",
    "    # define the model input\n",
    "    inputs = Input(shape=inputShape)\n",
    "\n",
    "    # loop over the number of filters\n",
    "    for (i, f) in enumerate(filters):\n",
    "        # if this is the first CONV layer then set the input\n",
    "        # appropriately\n",
    "        if i == 0:\n",
    "            x = inputs\n",
    "\n",
    "        # CONV => RELU => BN => POOL\n",
    "        x = Conv2D(f, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # flatten the volume, then FC => RELU => BN => DROPOUT\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(16)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # apply another FC layer, this one to match the number of nodes\n",
    "    # coming out of the MLP\n",
    "    x = Dense(4)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    # check to see if the regression node should be added\n",
    "    if regress:\n",
    "        x = Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "    # construct the CNN\n",
    "    model = Model(inputs, x)\n",
    "\n",
    "    # return the CNN\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# and batch size\n",
    "EPOCHS = 100\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "\n",
    "model = train_deep_net(width=64, height=64, depth=3, regress=True)\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt, metrics=[\"mae\"])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "history = model.fit(x_train_images, y_train,\n",
    "                    validation_data=(x_test_images, y_test),\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BS)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(x_test_images)\n",
    "diff = predictions.flatten() - y_test\n",
    "percentDiff = (diff / y_test) * 100\n",
    "absPercentDiff = np.abs(percentDiff)\n",
    "# compute the mean and standard deviation of the absolute percentage\n",
    "# difference\n",
    "mean = np.mean(absPercentDiff)\n",
    "std = np.std(absPercentDiff)\n",
    "# finally, show some statistics on our model\n",
    "locale.setlocale(locale.LC_ALL, \"en_US.UTF-8\")\n",
    "print(\"[INFO] avg. house price: {}, std house price: {}\".format(\n",
    "\tlocale.currency(df_train[\"price\"].mean(), grouping=True),\n",
    "\tlocale.currency(df_train[\"price\"].std(), grouping=True)))\n",
    "print(\"[INFO] mean: {:.2f}%, std: {:.2f}%\".format(mean, std))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}